1. 잠재 백터(랜덤 노이즈) -1에서 1사이로 정규화, generator 마지막 층 tanh
2. GAN논문에는 손실함수로 생성기인 경우 min(log 1-D)이지만 실정에서는 maxlogD사용=>생성자 학습할때 real=fake로 fake=real로 학습
(3. Uniform 분포가 아니라 가우시안 분포에서 샘플링)
(4. 배치정규화에서 미니 배치는 모두 실제 이미지거나 모두 생성된 미지를 사용해야함, 섞여서 들어가면 안됨)
//5. Sparse Gradients을 피하기 위해서는 LeakyReLU와 업스케일링인 경우 PixelShuffle, ConvTranspose2d(stride)사용 권장
6. 판별자 학습을 위한 라벨 smoothing, real=1과 fake=0대신 0.7~1.2 사이의 값으로 대체(R: 0.9/ F:0.1) 
7. DCGAN을 사용, 가능하지 않다면 하이브리드 모델인 KL+GAN/VAE+GAN 사용해라
8. 
9. 판별자는 SGD, 생성자는 Adam 사용
10. 판별자의 손실은 커져야하고 생성자의 손실이 꾸준히 줄어들어야한다.
11. 손실을 서로 맞추려고 하지마라, 손실이 커질때만 학습 x, 판별기와 생성기의 손실이 균형을 이룰 필요 x
(12. 라벨이 존재한다면 보조 GAN을 이용해서 샘플을 분류하는 판별기 학습)
//13.  판별기 입력에 인공적인 노이즈를 추가해라, 생선기 모든 계층에 가우시안 노이즈를 추가해라